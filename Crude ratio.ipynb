{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNOBmWKmAnz5"
      },
      "outputs": [],
      "source": [
        "from IPython.lib.display import YouTubeVideo\n",
        "from sklearn.linear_model import RidgeCV, Ridge, LassoCV, LinearRegression,Lasso\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "df = pd.read_excel('pH Relation.xlsx')\n",
        "#Clean DATE\n",
        "df['DATE'] = pd.to_datetime(df['DATE'])\n",
        "df['DATE'] = df['DATE'].dt.date\n",
        "\n",
        "#Delete blank\n",
        "df = df.dropna(subset=['pH'], axis=0)\n",
        "df = df.dropna(subset=['Ammonia/ppm'], axis=0)\n",
        "df = df.dropna(subset=['Sulfide/ppm'], axis=0)\n",
        "df = df.dropna(subset=['Chloride/ppm'], axis=0)\n",
        "# #Clean crude diet\n",
        "# label_encoder = LabelEncoder()\n",
        "# df['Numerical_diet'] = label_encoder.fit_transform(df['Crude diet'])\n",
        "\n",
        "# df['H+'] = df['pH'].apply(lambda x: math.exp(-x))\n",
        "# df['Ammonia/ppb'] = df['Ammonia/ppm']*1000\n",
        "# df['Sulfide/ppb'] = df['Sulfide/ppm']*1000\n",
        "# df['Chloride/ppb'] = df['Chloride/ppm']*1000\n",
        "#resetindex\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "#plot\n",
        "# sns.scatterplot(data = df, x = \"pH\", y='Ammonia/ppm')\n",
        "# plt.show()\n",
        "# sns.scatterplot(data = df, x = \"pH\", y='Sulfide/ppm')\n",
        "# plt.show()\n",
        "# sns.scatterplot(data = df, x = \"pH\", y='Chloride/ppm')\n",
        "# plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           DATE  IOW(In/Out)    pH  Ammonia/ppm  Sulfide/ppm  Chloride/ppm   \n",
            "0    2022-12-06            0   5.5          2.0        0.034        1.0200  \\\n",
            "1    2022-12-07            0   5.5          9.0        0.088        1.0280   \n",
            "2    2022-12-22            1  8.58         18.0        0.070        0.7090   \n",
            "3    2022-12-23            1  8.58         18.0        0.070        0.7090   \n",
            "4    2022-12-25            1  8.35         56.0        0.120        1.7564   \n",
            "..          ...          ...   ...          ...          ...           ...   \n",
            "134  2023-08-27            0  5.87         71.0        2.000        6.2000   \n",
            "135  2023-08-28            0  6.67         30.0        0.020        6.9127   \n",
            "136  2023-08-30            0  7.98         52.0        0.060        6.2037   \n",
            "137  2023-09-01            1  8.51         74.0        0.040        4.4312   \n",
            "138  2023-09-04            1     9         90.0        0.020        6.9127   \n",
            "\n",
            "     Iron/ppm  Oil&Grease/ppm  DO/ppm   \n",
            "0       0.500             0.0     6.0  \\\n",
            "1       0.610             0.0     7.0   \n",
            "2       0.516             0.0     4.0   \n",
            "3       0.516             0.0     4.0   \n",
            "4       0.117             0.0     3.5   \n",
            "..        ...             ...     ...   \n",
            "134     0.297             NaN     NaN   \n",
            "135     0.198            23.5     NaN   \n",
            "136     0.135             NaN     NaN   \n",
            "137     0.101             NaN     NaN   \n",
            "138     0.208             NaN     NaN   \n",
            "\n",
            "                                          Crude diet   \n",
            "0                       BEN-WTM-UJU-PAT-SIB-SHGO-GIR  \\\n",
            "1                       BEN-WTM-UJU-PAT-SIB-SHGO-GIR   \n",
            "2          GIR-UJU-WTM-SLGO-SIB-SHGO-SWD-KIS-JSM-SVD   \n",
            "3          GIR-UJU-WTM-SLGO-SIB-SHGO-SWD-KIS-JSM-SVD   \n",
            "4                        WTM-GIR-BEN-JSM-PAT-SIB-UJU   \n",
            "..                                               ...   \n",
            "134         GIR-MR1-PAT-SVD-JSM-MUR-SIB-MIN-WTM-SHGO   \n",
            "135         GIR-MR1-PAT-SVD-JSM-MUR-SIB-MIN-WTM-SHGO   \n",
            "136  GIR-PAT-CHI-JSM-BUG-MR1-MUR-SIB-SVD-WTM-RBL-LAB   \n",
            "137             GIR-CHA-PAT-JSM-SIB-MR1-SVD-MIN-UJU-   \n",
            "138              GIR-CHA-JSM-KIS-MR1-SVD-MUR-SIB-MIN   \n",
            "\n",
            "                    Crude ratio  \n",
            "0             32-23-17-17-5-3-2  \n",
            "1             32-23-17-17-5-3-3  \n",
            "2       25-15-14-11-9-8-7-6-4-1  \n",
            "3       25-15-14-11-9-8-7-6-4-1  \n",
            "4             30-22-17-17-6-5-2  \n",
            "..                          ...  \n",
            "134   34-20-19-10-7-3-3-2-1-1-1  \n",
            "135   34-20-19-10-7-3-3-2-1-1-1  \n",
            "136  44-17-15-6-6-4-4-2-1-1-1-1  \n",
            "137      44-16-15-6-6-5-3-2-1-1  \n",
            "138     27-26-18-15-6-3-2-2-1-1  \n",
            "\n",
            "[139 rows x 11 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DO/ppm</th>\n",
              "      <th>Crude diet</th>\n",
              "      <th>Crude ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>BEN-WTM-UJU-PAT-SIB-SHGO-GIR</td>\n",
              "      <td>32-23-17-17-5-3-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.0</td>\n",
              "      <td>BEN-WTM-UJU-PAT-SIB-SHGO-GIR</td>\n",
              "      <td>32-23-17-17-5-3-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.0</td>\n",
              "      <td>GIR-UJU-WTM-SLGO-SIB-SHGO-SWD-KIS-JSM-SVD</td>\n",
              "      <td>25-15-14-11-9-8-7-6-4-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>GIR-UJU-WTM-SLGO-SIB-SHGO-SWD-KIS-JSM-SVD</td>\n",
              "      <td>25-15-14-11-9-8-7-6-4-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.5</td>\n",
              "      <td>WTM-GIR-BEN-JSM-PAT-SIB-UJU</td>\n",
              "      <td>30-22-17-17-6-5-2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   DO/ppm                                 Crude diet              Crude ratio\n",
              "0     6.0               BEN-WTM-UJU-PAT-SIB-SHGO-GIR        32-23-17-17-5-3-2\n",
              "1     7.0               BEN-WTM-UJU-PAT-SIB-SHGO-GIR        32-23-17-17-5-3-3\n",
              "2     4.0  GIR-UJU-WTM-SLGO-SIB-SHGO-SWD-KIS-JSM-SVD  25-15-14-11-9-8-7-6-4-1\n",
              "3     4.0  GIR-UJU-WTM-SLGO-SIB-SHGO-SWD-KIS-JSM-SVD  25-15-14-11-9-8-7-6-4-1\n",
              "4     3.5                WTM-GIR-BEN-JSM-PAT-SIB-UJU        30-22-17-17-6-5-2"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = df.iloc[:,8:11]\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      BEN   WTM   UJU   PAT  SIB  SHGO   GIR  SLGO  SWD   KIS  ...  DAR  SUT   \n",
            "0    32.0  23.0  17.0  17.0    5   3.0   2.0   NaN  NaN   NaN  ...  NaN  NaN  \\\n",
            "1    32.0  23.0  17.0  17.0    5   3.0   3.0   NaN  NaN   NaN  ...  NaN  NaN   \n",
            "2     NaN  14.0  15.0   NaN    9   8.0  25.0  11.0  7.0   6.0  ...  NaN  NaN   \n",
            "3     NaN  14.0  15.0   NaN    9   8.0  25.0  11.0  7.0   6.0  ...  NaN  NaN   \n",
            "4    17.0  30.0   2.0   6.0    5   NaN  22.0   NaN  NaN   NaN  ...  NaN  NaN   \n",
            "..    ...   ...   ...   ...  ...   ...   ...   ...  ...   ...  ...  ...  ...   \n",
            "134   NaN   1.0   NaN  19.0    3   1.0  34.0   NaN  NaN   NaN  ...  NaN  NaN   \n",
            "135   NaN   1.0   NaN  19.0    3   1.0  34.0   NaN  NaN   NaN  ...  NaN  NaN   \n",
            "136   NaN   1.0   NaN  17.0    2   NaN  44.0   NaN  NaN   NaN  ...  NaN  NaN   \n",
            "137   NaN   NaN   1.0  15.0    6   NaN  44.0   NaN  NaN   NaN  ...  NaN  NaN   \n",
            "138   NaN   NaN   NaN   NaN    2   NaN  27.0   NaN  NaN  15.0  ...  NaN  NaN   \n",
            "\n",
            "      CHA  SSR  MAO  LAB  RBL   MR1  MAO.   CHI  \n",
            "0     NaN  NaN  NaN  NaN  NaN   NaN   NaN   NaN  \n",
            "1     NaN  NaN  NaN  NaN  NaN   NaN   NaN   NaN  \n",
            "2     NaN  NaN  NaN  NaN  NaN   NaN   NaN   NaN  \n",
            "3     NaN  NaN  NaN  NaN  NaN   NaN   NaN   NaN  \n",
            "4     NaN  NaN  NaN  NaN  NaN   NaN   NaN   NaN  \n",
            "..    ...  ...  ...  ...  ...   ...   ...   ...  \n",
            "134   NaN  NaN  NaN  NaN  NaN  20.0   NaN   NaN  \n",
            "135   NaN  NaN  NaN  NaN  NaN  20.0   NaN   NaN  \n",
            "136   NaN  NaN  NaN  1.0  1.0   4.0   NaN  15.0  \n",
            "137  16.0  NaN  NaN  NaN  NaN   5.0   NaN   NaN  \n",
            "138  26.0  NaN  NaN  NaN  NaN   6.0   NaN   NaN  \n",
            "\n",
            "[139 rows x 40 columns]\n"
          ]
        }
      ],
      "source": [
        "df_new = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    crude_list = row['Crude diet'].split('-')\n",
        "    ratio_list = list(map(int, row['Crude ratio'].split('-')))\n",
        "    \n",
        "    # Create a dictionary mapping crude names to their ratios\n",
        "    crude_ratio_dict = dict(zip(crude_list, ratio_list))\n",
        "    \n",
        "    # Convert the dictionary to a DataFrame and append to the list\n",
        "    df_new.append(pd.DataFrame([crude_ratio_dict]))\n",
        "\n",
        "# Concatenate the DataFrames\n",
        "result_df = pd.concat(df_new, ignore_index=True)\n",
        "\n",
        "print(result_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[   BEN  WTM  UJU  PAT  SIB  SHGO  GIR\n",
            "0   32   23   17   17    5     3    2,    BEN  WTM  UJU  PAT  SIB  SHGO  GIR\n",
            "0   32   23   17   17    5     3    3,    GIR  UJU  WTM  SLGO  SIB  SHGO  SWD  KIS  JSM  SVD\n",
            "0   25   15   14    11    9     8    7    6    4    1,    GIR  UJU  WTM  SLGO  SIB  SHGO  SWD  KIS  JSM  SVD\n",
            "0   25   15   14    11    9     8    7    6    4    1,    WTM  GIR  BEN  JSM  PAT  SIB  UJU\n",
            "0   30   22   17   17    6    5    2]\n"
          ]
        }
      ],
      "source": [
        "print(df_new[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      BEN   WTM   UJU   PAT  SIB  SHGO   GIR  SLGO  SWD   KIS  ...  DAR  SUT   \n",
            "0    32.0  23.0  17.0  17.0    5   3.0   2.0   NaN  NaN   NaN  ...  NaN  NaN  \\\n",
            "1    32.0  23.0  17.0  17.0    5   3.0   3.0   NaN  NaN   NaN  ...  NaN  NaN   \n",
            "2     NaN  14.0  15.0   NaN    9   8.0  25.0  11.0  7.0   6.0  ...  NaN  NaN   \n",
            "3     NaN  14.0  15.0   NaN    9   8.0  25.0  11.0  7.0   6.0  ...  NaN  NaN   \n",
            "4    17.0  30.0   2.0   6.0    5   NaN  22.0   NaN  NaN   NaN  ...  NaN  NaN   \n",
            "..    ...   ...   ...   ...  ...   ...   ...   ...  ...   ...  ...  ...  ...   \n",
            "134   NaN   1.0   NaN  19.0    3   1.0  34.0   NaN  NaN   NaN  ...  NaN  NaN   \n",
            "135   NaN   1.0   NaN  19.0    3   1.0  34.0   NaN  NaN   NaN  ...  NaN  NaN   \n",
            "136   NaN   1.0   NaN  17.0    2   NaN  44.0   NaN  NaN   NaN  ...  NaN  NaN   \n",
            "137   NaN   NaN   1.0  15.0    6   NaN  44.0   NaN  NaN   NaN  ...  NaN  NaN   \n",
            "138   NaN   NaN   NaN   NaN    2   NaN  27.0   NaN  NaN  15.0  ...  NaN  NaN   \n",
            "\n",
            "      CHA  SSR  MAO  LAB  RBL   MR1  MAO.   CHI  \n",
            "0     NaN  NaN  NaN  NaN  NaN   NaN   NaN   NaN  \n",
            "1     NaN  NaN  NaN  NaN  NaN   NaN   NaN   NaN  \n",
            "2     NaN  NaN  NaN  NaN  NaN   NaN   NaN   NaN  \n",
            "3     NaN  NaN  NaN  NaN  NaN   NaN   NaN   NaN  \n",
            "4     NaN  NaN  NaN  NaN  NaN   NaN   NaN   NaN  \n",
            "..    ...  ...  ...  ...  ...   ...   ...   ...  \n",
            "134   NaN  NaN  NaN  NaN  NaN  20.0   NaN   NaN  \n",
            "135   NaN  NaN  NaN  NaN  NaN  20.0   NaN   NaN  \n",
            "136   NaN  NaN  NaN  1.0  1.0   4.0   NaN  15.0  \n",
            "137  16.0  NaN  NaN  NaN  NaN   5.0   NaN   NaN  \n",
            "138  26.0  NaN  NaN  NaN  NaN   6.0   NaN   NaN  \n",
            "\n",
            "[139 rows x 40 columns]\n"
          ]
        }
      ],
      "source": [
        "df_combined = pd.concat(df_new, ignore_index=True)\n",
        "print(df_combined)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      BEN   WTM   UJU   PAT  SIB  SHGO   GIR  SLGO  SWD   KIS  ...  DAR  SUT   \n",
            "0    32.0  23.0  17.0  17.0    5   3.0   2.0   0.0  0.0   0.0  ...  0.0  0.0  \\\n",
            "1    32.0  23.0  17.0  17.0    5   3.0   3.0   0.0  0.0   0.0  ...  0.0  0.0   \n",
            "2     0.0  14.0  15.0   0.0    9   8.0  25.0  11.0  7.0   6.0  ...  0.0  0.0   \n",
            "3     0.0  14.0  15.0   0.0    9   8.0  25.0  11.0  7.0   6.0  ...  0.0  0.0   \n",
            "4    17.0  30.0   2.0   6.0    5   0.0  22.0   0.0  0.0   0.0  ...  0.0  0.0   \n",
            "..    ...   ...   ...   ...  ...   ...   ...   ...  ...   ...  ...  ...  ...   \n",
            "134   0.0   1.0   0.0  19.0    3   1.0  34.0   0.0  0.0   0.0  ...  0.0  0.0   \n",
            "135   0.0   1.0   0.0  19.0    3   1.0  34.0   0.0  0.0   0.0  ...  0.0  0.0   \n",
            "136   0.0   1.0   0.0  17.0    2   0.0  44.0   0.0  0.0   0.0  ...  0.0  0.0   \n",
            "137   0.0   0.0   1.0  15.0    6   0.0  44.0   0.0  0.0   0.0  ...  0.0  0.0   \n",
            "138   0.0   0.0   0.0   0.0    2   0.0  27.0   0.0  0.0  15.0  ...  0.0  0.0   \n",
            "\n",
            "      CHA  SSR  MAO  LAB  RBL   MR1  MAO.   CHI  \n",
            "0     0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0  \n",
            "1     0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0  \n",
            "2     0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0  \n",
            "3     0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0  \n",
            "4     0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0  \n",
            "..    ...  ...  ...  ...  ...   ...   ...   ...  \n",
            "134   0.0  0.0  0.0  0.0  0.0  20.0   0.0   0.0  \n",
            "135   0.0  0.0  0.0  0.0  0.0  20.0   0.0   0.0  \n",
            "136   0.0  0.0  0.0  1.0  1.0   4.0   0.0  15.0  \n",
            "137  16.0  0.0  0.0  0.0  0.0   5.0   0.0   0.0  \n",
            "138  26.0  0.0  0.0  0.0  0.0   6.0   0.0   0.0  \n",
            "\n",
            "[139 rows x 40 columns]\n"
          ]
        }
      ],
      "source": [
        "df_combined = df_combined.fillna(0)\n",
        "print(df_combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_merged = pd.concat([df, df_combined], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           DATE  IOW(In/Out)    pH  Ammonia/ppm  Sulfide/ppm  Chloride/ppm   \n",
            "0    2022-12-06            0   5.5          2.0        0.034        1.0200  \\\n",
            "1    2022-12-07            0   5.5          9.0        0.088        1.0280   \n",
            "2    2022-12-22            1  8.58         18.0        0.070        0.7090   \n",
            "3    2022-12-23            1  8.58         18.0        0.070        0.7090   \n",
            "4    2022-12-25            1  8.35         56.0        0.120        1.7564   \n",
            "..          ...          ...   ...          ...          ...           ...   \n",
            "134  2023-08-27            0  5.87         71.0        2.000        6.2000   \n",
            "135  2023-08-28            0  6.67         30.0        0.020        6.9127   \n",
            "136  2023-08-30            0  7.98         52.0        0.060        6.2037   \n",
            "137  2023-09-01            1  8.51         74.0        0.040        4.4312   \n",
            "138  2023-09-04            1     9         90.0        0.020        6.9127   \n",
            "\n",
            "     Iron/ppm  Oil&Grease/ppm  DO/ppm   \n",
            "0       0.500             0.0     6.0  \\\n",
            "1       0.610             0.0     7.0   \n",
            "2       0.516             0.0     4.0   \n",
            "3       0.516             0.0     4.0   \n",
            "4       0.117             0.0     3.5   \n",
            "..        ...             ...     ...   \n",
            "134     0.297             NaN     NaN   \n",
            "135     0.198            23.5     NaN   \n",
            "136     0.135             NaN     NaN   \n",
            "137     0.101             NaN     NaN   \n",
            "138     0.208             NaN     NaN   \n",
            "\n",
            "                                          Crude diet  ...  DAR  SUT   CHA   \n",
            "0                       BEN-WTM-UJU-PAT-SIB-SHGO-GIR  ...  0.0  0.0   0.0  \\\n",
            "1                       BEN-WTM-UJU-PAT-SIB-SHGO-GIR  ...  0.0  0.0   0.0   \n",
            "2          GIR-UJU-WTM-SLGO-SIB-SHGO-SWD-KIS-JSM-SVD  ...  0.0  0.0   0.0   \n",
            "3          GIR-UJU-WTM-SLGO-SIB-SHGO-SWD-KIS-JSM-SVD  ...  0.0  0.0   0.0   \n",
            "4                        WTM-GIR-BEN-JSM-PAT-SIB-UJU  ...  0.0  0.0   0.0   \n",
            "..                                               ...  ...  ...  ...   ...   \n",
            "134         GIR-MR1-PAT-SVD-JSM-MUR-SIB-MIN-WTM-SHGO  ...  0.0  0.0   0.0   \n",
            "135         GIR-MR1-PAT-SVD-JSM-MUR-SIB-MIN-WTM-SHGO  ...  0.0  0.0   0.0   \n",
            "136  GIR-PAT-CHI-JSM-BUG-MR1-MUR-SIB-SVD-WTM-RBL-LAB  ...  0.0  0.0   0.0   \n",
            "137             GIR-CHA-PAT-JSM-SIB-MR1-SVD-MIN-UJU-  ...  0.0  0.0  16.0   \n",
            "138              GIR-CHA-JSM-KIS-MR1-SVD-MUR-SIB-MIN  ...  0.0  0.0  26.0   \n",
            "\n",
            "     SSR  MAO  LAB  RBL   MR1  MAO.   CHI  \n",
            "0    0.0  0.0  0.0  0.0   0.0   0.0   0.0  \n",
            "1    0.0  0.0  0.0  0.0   0.0   0.0   0.0  \n",
            "2    0.0  0.0  0.0  0.0   0.0   0.0   0.0  \n",
            "3    0.0  0.0  0.0  0.0   0.0   0.0   0.0  \n",
            "4    0.0  0.0  0.0  0.0   0.0   0.0   0.0  \n",
            "..   ...  ...  ...  ...   ...   ...   ...  \n",
            "134  0.0  0.0  0.0  0.0  20.0   0.0   0.0  \n",
            "135  0.0  0.0  0.0  0.0  20.0   0.0   0.0  \n",
            "136  0.0  0.0  1.0  1.0   4.0   0.0  15.0  \n",
            "137  0.0  0.0  0.0  0.0   5.0   0.0   0.0  \n",
            "138  0.0  0.0  0.0  0.0   6.0   0.0   0.0  \n",
            "\n",
            "[139 rows x 51 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df_merged)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "T5knUYk09PjG"
      },
      "outputs": [],
      "source": [
        "excel_file = \"export01.xlsx\"\n",
        "df_merged.to_excel(excel_file, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "fgPWSnhvpVCh"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[59], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Split data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X_train, X_test, Y_train, Y_test \u001b[39m=\u001b[39m train_test_split(X, Y, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Split data\n",
        "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UbNjAXoK0T7",
        "outputId": "bab6d7b3-f58e-4f3f-839c-dc208f689ab3"
      },
      "outputs": [],
      "source": [
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Step 5: Train the Decision Tree classifier on the training data\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "# Step 6: Make predictions on the testing data\n",
        "Y_pred = clf.predict(X_test)\n",
        "\n",
        "# Step 7: Evaluate the model's performance\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# You can also print a classification report for more detailed metrics\n",
        "# classification_rep = classification_report(Y_test, Y_pred, target_names=\"Out IOW\")\n",
        "# print(\"Classification Report:\\n\", classification_rep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "ZO6PRk_X8KW1",
        "outputId": "44834e91-a8e2-496a-e7b1-f2d2ea559dd2"
      },
      "outputs": [],
      "source": [
        "# Find correlation\n",
        "# df = df[['H+','Ammonia/ppb', 'Sulfide/ppb', 'Chloride/ppb']]\n",
        "df = df[['pH','Ammonia/ppm', 'Sulfide/ppm', 'Chloride/ppm','']]\n",
        "correlation_matrix = df.corr()\n",
        "correlation_matrix\n",
        "# Create a correlation heatmap\n",
        "plt.figure(figsize=(9, 7))  # Set the size of the heatmap\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "\n",
        "\n",
        "\n",
        "# Show the plot\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "N1na0eX0pVKx",
        "outputId": "f65fb560-8b65-4734-d2a8-66f132fbe41d"
      },
      "outputs": [],
      "source": [
        "#Regression\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, Y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IndXYPMrpVOp"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "Y_pred = model.predict(X_test)\n",
        "# sns.scatterplot(data = df, x = \"Y_test\", y='Y_pred')\n",
        "# plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UctUcVTCpVSD"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "mse = mean_squared_error(Y_test, Y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r1 = r2_score(Y_test, Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bNTp7D7plbw",
        "outputId": "91c77d86-2387-4633-c680-30af51518492"
      },
      "outputs": [],
      "source": [
        "print(\"Evaluation\")\n",
        "\n",
        "print(\"MSE\",mse)\n",
        "print(\"RMSE\",rmse)\n",
        "print(f'R-squared : {r1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wqcRSPW1iZt"
      },
      "outputs": [],
      "source": [
        "#Scale data\n",
        "scaler = StandardScaler(with_mean=True, with_std=True)\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ_fQj-YwG_-",
        "outputId": "5bcf7a17-800f-495c-80eb-b1fc89ae16a8"
      },
      "outputs": [],
      "source": [
        "#ทำ Ridge Regularization เพื่อ improve model\n",
        "#ทำ Hyperparameter tuning บน training set โดยใช้ k-fold crossvalidation เพื่อหา best hyperparameter\n",
        "\n",
        "reg = RidgeCV(alphas=np.logspace(-10, 10, 1000),\n",
        "              cv=KFold(n_splits=10, shuffle=True),\n",
        "              scoring='neg_root_mean_squared_error')\n",
        "reg.fit(X_train_scaled, Y_train)\n",
        "print(\"Best alpha : \", reg.alpha_ )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8QXLu751yuh",
        "outputId": "6918039c-095b-4f15-a5e3-2a884bbe30de"
      },
      "outputs": [],
      "source": [
        "#นำ best hyperparameter มา train บน training set\n",
        "ridge = Ridge(alpha=reg.alpha_)\n",
        "ridge.fit(X_train_scaled, Y_train)\n",
        "print(\"Ridge Regression: \\n\")\n",
        "print(\"Mean squared error (MSE) = {}\".format(metrics.mean_squared_error(Y_test, ridge.predict(X_test_scaled))))\n",
        "print(f'Root mean squared error (RMSE):{np.sqrt(metrics.mean_squared_error(Y_test, ridge.predict(X_test_scaled)))}')\n",
        "y2_pred = ridge.predict(X_test_scaled)\n",
        "r2 = r2_score(Y_test, y2_pred)\n",
        "print(f'R-squared : {r2}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKGrX5Pr2Cq4",
        "outputId": "213cbe2a-2a7f-49a5-bd3d-4e1105cac874"
      },
      "outputs": [],
      "source": [
        "#ทำ Lasso Regularization เพื่อ improve model\n",
        "#ทำ Hyperparameter tuning บน training set โดยใช้ k-fold crossvalidation เพื่อหา best hyperparameter\n",
        "lasso = LassoCV(alphas=np.logspace(-10, 10, 1000),\n",
        "              cv=KFold(n_splits=10, shuffle=True))\n",
        "lasso.fit(X_train_scaled, Y_train)\n",
        "print(\"Best alpha : \", lasso.alpha_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG5Vkd1d2GEq",
        "outputId": "5b85d744-062e-4381-ce53-2373968b9099"
      },
      "outputs": [],
      "source": [
        "#นำ best hyperparameter มา train บน training set\n",
        "lasso_a = Lasso(alpha=lasso.alpha_)\n",
        "lasso_a.fit(X_train_scaled, Y_train)\n",
        "print(\"Lasso Regression: \\n\")\n",
        "print(\"Mean squared error (MSE) = {}\".format(metrics.mean_squared_error(Y_test, lasso_a.predict(X_test_scaled))))\n",
        "print(f'Root mean squared error (RMSE): {np.sqrt(metrics.mean_squared_error(Y_test, lasso_a.predict(X_test_scaled)))}')\n",
        "y_pred = lasso_a.predict(X_test_scaled)\n",
        "r = r2_score(Y_test, y_pred)\n",
        "print(f'R-squared : {r}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmzajI3F2dB5",
        "outputId": "5304f49f-3509-43b2-a016-d6e7bc04e10a"
      },
      "outputs": [],
      "source": [
        "#ทำ Exponential Regression model โดย improve model ด้วย Lasso Regularization\n",
        "degree = 2\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_poly = scaler.fit_transform(X_train)\n",
        "X_test_poly = scaler.transform(X_test)\n",
        "\n",
        "# Create a Polynomial Features transformer\n",
        "poly_features = PolynomialFeatures(degree=degree)\n",
        "X_train_poly = poly_features.fit_transform(X_train_poly)\n",
        "X_test_poly = poly_features.fit_transform(X_test_poly)\n",
        "\n",
        "\n",
        "# Create and train the Lasso Regression model\n",
        "lasso_poly = LassoCV(alphas=np.logspace(-10, 10, 1000),\n",
        "              cv=KFold(n_splits=10, shuffle=True))\n",
        "lasso_poly.fit(X_train_poly, Y_train)\n",
        "\n",
        "lasso_polyb = Lasso(alpha=lasso_poly.alpha_)\n",
        "lasso_polyb.fit(X_train_poly, Y_train)\n",
        "\n",
        "print('Lasso Exponential Regression: \\n')\n",
        "\n",
        "print(\"Best alpha = {}, MSE = {}\".format(lasso_poly.alpha_, metrics.mean_squared_error(Y_test, lasso_polyb.predict(X_test_poly))))\n",
        "print(f'RMSE = {np.sqrt(metrics.mean_squared_error(Y_test, lasso_polyb.predict(X_test_poly)))}')\n",
        "y4_pred = lasso_polyb.predict(X_test_poly)\n",
        "r4 = r2_score(Y_test, y4_pred)\n",
        "print(f'R-squared : {r4}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slEQWWnz3Vft",
        "outputId": "2b2125aa-c6f7-46cc-cd02-0b7f728eec4c"
      },
      "outputs": [],
      "source": [
        "#ทำ Exponential Regression model โดย improve model ด้วย Ridge Regularization\n",
        "degree = 2\n",
        "# Standardize the features\n",
        "scaler_r = StandardScaler()\n",
        "X_train_poly_r = scaler_r.fit_transform(X_train)\n",
        "X_test_poly_r = scaler_r.fit_transform(X_test)\n",
        "\n",
        "# Create a Polynomial Features transformer\n",
        "poly_features_r = PolynomialFeatures(degree=degree)\n",
        "X_train_poly_r = poly_features_r.fit_transform(X_train_poly_r)\n",
        "X_test_poly_r = poly_features_r.fit_transform(X_test_poly_r)\n",
        "\n",
        "# Create and train the Lasso Regression model\n",
        "ridge_poly = RidgeCV(alphas=np.logspace(-10, 10, 1000),\n",
        "              cv=KFold(n_splits=10, shuffle=True))\n",
        "ridge_poly.fit(X_train_poly_r, Y_train)\n",
        "\n",
        "lin_poly = Ridge(alpha=ridge_poly.alpha_)\n",
        "lin_poly.fit(X_train_poly_r, Y_train)\n",
        "\n",
        "print('Ridge Exponential Regression: \\n')\n",
        "\n",
        "print(\"Best alpha = {}, MSE = {}\".format(ridge_poly.alpha_, metrics.mean_squared_error(Y_test, lin_poly.predict(X_test_poly_r))))\n",
        "print(f'RMSE = {np.sqrt(metrics.mean_squared_error(Y_test, lin_poly.predict(X_test_poly_r)))}')\n",
        "y5_pred = lin_poly.predict(X_test_poly_r)\n",
        "r5 = r2_score(Y_test, y5_pred)\n",
        "\n",
        "print(f'R-squared : {r5}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
